{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Date       Open       High        Low      Close  Adj Close  Volume\n",
      "0 2016-01-08  19.162428  19.162428  19.114038  19.114038  11.411459   10300\n",
      "1 2016-01-11  19.133394  19.230173  19.017258  19.017258  11.353675   49600\n",
      "2 2016-01-12  19.113070  19.113070  19.103392  19.103392  11.405104    2300\n",
      "3 2016-01-13  19.103392  19.103392  19.103392  19.103392  11.405104       0\n",
      "4 2016-01-14  19.065647  19.385021  18.968868  19.104361  11.405683   26100\n",
      "              Open         High          Low        Close    Adj Close  \\\n",
      "count  1065.000000  1065.000000  1065.000000  1065.000000  1065.000000   \n",
      "mean     18.249711    18.371465    18.103308    18.236492    14.059059   \n",
      "std       1.741026     1.721080     1.769183     1.737220     1.713009   \n",
      "min       9.260000    10.550000     8.650000     9.570000     9.262057   \n",
      "25%      16.770000    16.863323    16.666666    16.759096    12.676388   \n",
      "50%      18.544971    18.688206    18.377581    18.533358    14.464704   \n",
      "75%      19.404377    19.469027    19.301868    19.400507    15.445642   \n",
      "max      21.160275    21.269421    21.081612    21.189774    16.787027   \n",
      "\n",
      "              Volume  \n",
      "count    1065.000000  \n",
      "mean    44223.286385  \n",
      "std     44650.220412  \n",
      "min         0.000000  \n",
      "25%     17600.000000  \n",
      "50%     32100.000000  \n",
      "75%     54600.000000  \n",
      "max    385200.000000  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Define the dataset folder\n",
    "DATASET_PATH = \"dataset\"\n",
    "\n",
    "# Load metadata\n",
    "meta_file = os.path.join(DATASET_PATH, \"symbols_valid_meta.csv\")\n",
    "meta_df = pd.read_csv(meta_file)\n",
    "\n",
    "# Function to clean stock data\n",
    "def clean_stock_data(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Convert Date column to datetime\n",
    "    df[\"Date\"] = pd.to_datetime(df[\"Date\"], errors='coerce')\n",
    "    \n",
    "    # Ensure numerical columns are in the correct format\n",
    "    numeric_cols = [\"Open\", \"High\", \"Low\", \"Close\", \"Adj Close\", \"Volume\"]\n",
    "    df[numeric_cols] = df[numeric_cols].apply(pd.to_numeric, errors='coerce')\n",
    "    \n",
    "    # Drop rows with missing Date\n",
    "    df = df.dropna(subset=[\"Date\"])\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Process all stock and ETF files\n",
    "stocks_path = os.path.join(DATASET_PATH, \"stocks\")\n",
    "etfs_path = os.path.join(DATASET_PATH, \"ETFs\")\n",
    "\n",
    "cleaned_data = {}\n",
    "\n",
    "for folder in [stocks_path, etfs_path]:\n",
    "    for file in os.listdir(folder):\n",
    "        if file.endswith(\".csv\"):\n",
    "            file_path = os.path.join(folder, file)\n",
    "            df_cleaned = clean_stock_data(file_path)\n",
    "            cleaned_data[file] = df_cleaned\n",
    "\n",
    "# Example: Display cleaned data for a sample stock\n",
    "ticker_sample = list(cleaned_data.keys())[0]\n",
    "print(cleaned_data[ticker_sample].head())\n",
    "print(cleaned_data[ticker_sample].describe())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
